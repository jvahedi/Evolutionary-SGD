{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T22:18:33.816503Z",
     "start_time": "2021-04-03T22:18:33.797185Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T22:57:06.069846Z",
     "start_time": "2021-04-03T22:57:06.048308Z"
    }
   },
   "outputs": [],
   "source": [
    "#INPUT:\n",
    "#L: list to randomly choose subset from\n",
    "#k: k sized subset tp pick from array\n",
    "#OUTPUT:\n",
    "#subset: the random subset array picked from original list\n",
    "def rand_subset(L, k):\n",
    "    s = len(L)\n",
    "    items = np.linspace(0,s-1,s).astype(int)\n",
    "    np.random.shuffle(items)\n",
    "    index = items[:k]\n",
    "    L = np.array(L)\n",
    "    subset = L[index]\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T23:46:47.020506Z",
     "start_time": "2021-04-03T23:46:47.012943Z"
    }
   },
   "outputs": [],
   "source": [
    "#INPUT:\n",
    "#arr: array of values\n",
    "#n: top n to return\n",
    "#OUTPUT:\n",
    "# elements: largest n elements in list returned as array \n",
    "def selection(arr, n):\n",
    "    arr = -np.array(arr)\n",
    "    arr_sort = -np.sort(arr)\n",
    "    elements = arr_sort[:n]\n",
    "    return elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUTS:\n",
    "#subset: array of old polulation\n",
    "#L: list of all possible people in population\n",
    "# k: size of subset, the old population \n",
    "# n: number of top people kept from last population in subset\n",
    "#\n",
    "#OUTPUTS:\n",
    "#population: new iteration of list including\n",
    "#           elements of last list and and randomized\n",
    "#           rest of subset population.\n",
    "def repopulate(subset,L, k, n):\n",
    "    #amount r needed to repopulate\n",
    "    r = k - n\n",
    "    #remove elements already included\n",
    "    remain = np.setdiff1d(L,subset)\n",
    "    # pick r new people\n",
    "    rest = rand_subset(remain, r)\n",
    "    #new people join old population\n",
    "    new_pop = np.concatenate((subset, rest))\n",
    "    return new_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T05:40:23.782053Z",
     "start_time": "2021-04-10T05:40:23.754292Z"
    }
   },
   "outputs": [],
   "source": [
    "#Imagine minimization problem: F*a=y (or a*f(x)=y, a linear parameter)\n",
    "#Find the a that gets F*a closest to y\n",
    "#F is mxn matrix with columns populated\n",
    "#by n different f_j(x) functions or features\n",
    "#a is n-vector, y is an m-vector\n",
    "#We are optimizing over a's \n",
    "#but stochastic over the choice i's,\n",
    "#the different row of equations\n",
    "# which is also the equivalent number of loss fucntions\n",
    "\n",
    "#Possible function space \n",
    "#(create your own, make sure to update both)\n",
    "#a: parameters needing optimization (size n), use numpy array\n",
    "#x: 1d positional scalar \n",
    "#   (may have n variational functionals f_j(x) )\n",
    "#   i.e, a_0*f_0(x)+a_1*f_1(x)+...+a_n*f_n(x)\n",
    "\n",
    "def F(x):\n",
    "    return np.array([1,x,x**2,x**3])\n",
    "\n",
    "def f(a,x) :\n",
    "    #x = .7\n",
    "    #a = [1,3,5,4]\n",
    "    #F = np.array([1,x,x**2,x**3])\n",
    "    F1 = F(x)\n",
    "    return np.dot(a,F1)\n",
    "\n",
    "#Exact gradient of f(a,x), linear in a, in respect to 'a'\n",
    "def grad_f(a,x):\n",
    "    #x = .7\n",
    "    #a = [1,3,5,4]\n",
    "    grad_F = F(x)\n",
    "    return np.dot(a,grad_F)\n",
    "\n",
    "#Possible optional generator of data y\n",
    "#Instead import your own data\n",
    "#a linear factors (numpy array)\n",
    "#x x values in f(a,x) (scalar or numpy array)\n",
    "#s: variance/size of noise\n",
    "#norm: variance dependence on size of f(a,x)\n",
    "\n",
    "def Y(a,x,s = 1, norm = False):\n",
    "    m = x.size\n",
    "    if norm == False:\n",
    "        return np.array([x, f(a,x) + np.random.normal(0,s,m)])\n",
    "    else:\n",
    "        f0 = f(a,x)\n",
    "        nor = np.zeros(m)\n",
    "        for i in range(m):\n",
    "            nor[i] = np.absolute(f0[i])\n",
    "        return np.array([x,f0 + nor*np.random.normal(0,s,m)])\n",
    "            \n",
    "#Example loss function to be optimized\n",
    "#Note the f(a,x) is better updated as\n",
    "#a global variable between iterations\n",
    "\n",
    "#a: array of linear coefficients\n",
    "#x: scalar of oordinate\n",
    "#y: scalar of coordiante \n",
    "def phi(a,x,y):\n",
    "    return (f(a,x) - y)^2\n",
    "\n",
    "\n",
    "#Given phi loss function above\n",
    "#Local Gradient\n",
    "def grad_phi(a,x,y):\n",
    "    return 2*(f(a,x)-y)*grad_f(a,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T06:18:27.977040Z",
     "start_time": "2021-04-10T06:18:27.961418Z"
    }
   },
   "outputs": [],
   "source": [
    "#Main Evolutionary Stochastic Gradient Descent Algorithm\n",
    "#INPUTS:\n",
    "#a0: intial guess for parameters a (can be randomly assigned or zero vector)\n",
    "#C: coordinate data [x,y] x grouped and y grouped\n",
    "#K: size of stochastic subset of data to gradient-step in\n",
    "#eta: learning-rate/stepping size\n",
    "#num: number of iterations/steps\n",
    "#OUTPUT:\n",
    "\n",
    "def evSGD(a0, C, eta, K, num):\n",
    "    #size of Operator\n",
    "    m = np.size(C,1)\n",
    "    n = np.size(a0)\n",
    "    \n",
    "    A = np.array((num,n))\n",
    "    A[0] = a0\n",
    "    L = [i for i in range(m)]\n",
    "    \n",
    "    #initialize subset choice\n",
    "    L_k = rand_subset(L,K)\n",
    "    \n",
    "    for l in range(1,Num):\n",
    "        #updating new 'a' value\n",
    "        G = np.zeros(m)\n",
    "        for j in L_k:\n",
    "            G = G + grad_phi(A[l-1],C[0][j],C[1][j])\n",
    "\n",
    "        A[l] = A[l-1] - eta*G\n",
    "        \n",
    "        #reseting the population before next iteration\n",
    "        fittest = selection\n",
    "        \n",
    "    return A\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
